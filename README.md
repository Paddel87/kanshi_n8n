# Kanshi_n8n ğŸ§©ğŸ“½ï¸

Ein modularer Workflowâ€‘Stack fÃ¼r Mediaâ€‘Ingestion, Analyse und Verwaltung â€“ basierend auf n8n, NocoDB, PostgreSQL/TimescaleDB und MinIO. Semantische Analysen erfolgen vorerst Ã¼ber Grok (xAI). Der Stack ist fÃ¼r Windows 11 + Docker Desktop optimiert und lauffÃ¤hig im lokalen Setup.

## âœ¨ Features
- ğŸ“¥ Dragâ€‘andâ€‘Drop Mediaâ€‘Ingestion (via eigenes Webâ€‘UI + n8n Webhook)
- ğŸ§  Semantik Ã¼ber Grok (Tags, Summary als JSON)
- ğŸ—ƒï¸ Speicherung in Postgres (`media_analysis` JSONB + Text)
- ğŸ—‚ï¸ NocoDBâ€‘UI fÃ¼r CRUD, Views und einfache Auswertungen
- ğŸ§¾ MinIO als S3â€‘Speicher (optional: `/import`, `/frames`)
- âš™ï¸ Erweiterbar: Pose/Outfit/Restraints/ReID via ONNXâ€‘Runtime (spÃ¤ter)

## ğŸ§± Komponenten
- **n8n** (`http://localhost:5678`): Workflows, Webhooks, HTTPâ€‘Nodes
- **NocoDB** (`http://localhost:8080`): SQLâ€‘UI, Tabellen/Views, APIs
- **PostgreSQL/TimescaleDB** (`localhost:5432`): Datenbank, `media_analysis`
- **MinIO** (`http://localhost:9000`, Console `http://localhost:9001`): S3â€‘kompatibel

## ğŸ“¦ Verzeichnisstruktur
```
.
â”œâ”€ web/                     # Einfaches Drag&Dropâ€‘UI (index.html)
â”œâ”€ workflows/               # n8n Workflows (JSON)
â”‚  â””â”€ ingestion_grok.json   # Webhook â†’ Grok â†’ JSON speichern/Antwort
â”œâ”€ docs/
â”‚  â””â”€ Zugangsdaten.md       # Lokale Endpunkte und Zugangsdaten (sensibel)
â”œâ”€ data/                    # Persistente Dateien (JSONâ€‘Analysen etc.)
â”œâ”€ docker-compose.yml       # Fullâ€‘Stack (n8n + NocoDB + DB + MinIO)
â”œâ”€ docker-compose-minimal.yml# Minimalâ€‘Stack (nur n8n + NocoDB)
â”œâ”€ Dockerfile               # Custom n8n (FFmpeg)
â”œâ”€ init.sql                 # DBâ€‘Schema (TimescaleDB + pgvector)
â”œâ”€ .env                     # Lokale Secrets (nicht committen)
â””â”€ .env.example             # Beispielâ€‘Env mit Platzhaltern
```

## ğŸš€ Quickstart
1. ğŸ§© Voraussetzungen:
   - Windows 11 + Docker Desktop (WSL2 aktiviert)
   - Portâ€‘Freigaben: `5432`, `5678`, `8080`, `9000`, `9001`
2. ğŸ”‘ `.env` erstellen:
   - Kopiere `.env.example` â†’ `.env` und setze deine Werte:
     - `DB_PASSWORD`, `N8N_PASSWORD`, `GROK_API_KEY`, `S3_ACCESS`, `S3_SECRET`
3. â–¶ï¸ Stack starten:
   - `docker compose up -d`
4. ğŸ–¥ï¸ Zugriff:
   - n8n: `http://localhost:5678` (Login: `admin` / `N8N_PASSWORD`)
   - NocoDB: `http://localhost:8080`
   - MinIO Console: `http://localhost:9001`
5. ğŸ”Œ Workflow importieren & aktivieren:
   - n8n â†’ Import â†’ `workflows/ingestion_grok.json` â†’ aktivieren (Webhook: `/webhook/ingest`)
6. ğŸ§ª Drag&Drop testen:
   - Ã–ffne `web/index.html` im Browser
   - Ziehe eine Datei in die Dropâ€‘Zone
   - Ergebnis (Tags, Summary) wird angezeigt

## âš™ï¸ Konfiguration
- **NocoDB Metaâ€‘DB**: Standard ist SQLite (stabil). Bei Bedarf Postgres aktivieren:
  - Setze `NC_DB` in `docker-compose.yml` auf eine gÃ¼ltige URL
  - Empfohlen: `postgres://postgres:${DB_PASSWORD}@db:5432/kanshi`
- **Postgresâ€‘Schema**:
  - `init.sql` wird beim ersten Start eingespielt
  - Tabelle `media_analysis` enthÃ¤lt: `filename`, `hash`, `tags` (JSONB), `summary`, `ts`
- **MinIO Buckets**:
  - Console `http://localhost:9001` â†’ Erstelle optional `/import`, `/frames`
- **Grok API**:
  - `.env` â†’ `GROK_API_KEY` (xAI)
  - Endpoint: `https://api.x.ai/v1/chat/completions`

## ğŸ§° NÃ¼tzliche Kommandos
- ğŸ” Status:
  - `docker ps`
  - `docker compose logs -f`
- ğŸ§¼ Neu starten:
  - `docker compose down && docker compose up -d`
- ğŸ§ª Logs prÃ¼fen:
  - NocoDB: `docker logs kanshi_n8n-ui-1 --tail 120`
  - DB: `docker logs kanshi_n8n-db-1 --tail 100`
- ğŸ—„ï¸ DBâ€‘Query:
  - `docker exec kanshi_n8n-db-1 psql -U postgres -d kanshi -c "SELECT * FROM media_analysis LIMIT 5;"`

## ğŸ§© Workflows
- `workflows/ingestion_grok.json`
  - Webhook â†’ Hash (Code) â†’ Grok (HTTP) â†’ JSON speichern â†’ Response
  - Speicherpfad: `data/analyses/<hash>.json`
  - Erweiterung: Insert in `media_analysis` via n8n SQLite/Postgresâ€‘Node

## ğŸ› ï¸ Troubleshooting
- ğŸ” NocoDB startet neu (â€œInvalid URLâ€ / â€œDatabase not supportedâ€):
  - PrÃ¼fe `NC_DB` in `docker-compose.yml` â†’ nutze `sqlite` oder eine gÃ¼ltige Postgresâ€‘URL
- ğŸ§± DB Hypertable Warnung:
  - Timescaleâ€‘Hinweis (PK vs Partition Column) â†’ Service lÃ¤uft trotzdem.
  - Fix optional: PK auf `PRIMARY KEY (id, created_at)` Ã¤ndern und `created_at` zu `TIMESTAMPTZ`.
- ğŸ”’ Unauthorized bei n8nâ€‘REST API:
  - RESTâ€‘API erwartet UIâ€‘Session; importiere Workflows via UI

## ğŸ” Sicherheit
- `.env` niemals committen
- Nutze starke PasswÃ¶rter (`DB_PASSWORD`, `N8N_PASSWORD`)
- Optional: Traefik / TLS fÃ¼r Produktion

## ğŸ—ºï¸ Roadmap
- ğŸ§  KIâ€‘Modelle (OpenPose, RFâ€‘DETR, RTâ€‘DETR, OSNet) via ONNX
- ğŸ§® pgvector und ReIDâ€‘Suchen
- ğŸ“Š Dashboards (Metabase) fÃ¼r Stats
- ğŸ§¼ Wartung: Autoâ€‘Cleanup (Frames >90 Tage), Backups

## ğŸ“š Referenzen
- `docs/Zugangsdaten.md` â€“ Ãœbersicht der lokalen Endpunkte/ZugÃ¤nge
- `Pflichtenheft.md` â€“ Anforderungen, Architektur, Workflows
- Offizielle Docs: n8n, NocoDB, TimescaleDB, MinIO, xAI Grok

---

> ğŸ’¡ Hinweis: Dieses Repo ist lokal lauffÃ¤hig. FÃ¼r GPU/ROCm UnterstÃ¼tzung unter WSL2 sind zusÃ¤tzliche Schritte nÃ¶tig; aktuell ist CPU der Default.
